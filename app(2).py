
from tqdm import tqdm
import os
import google.generativeai as genai
from dotenv import load_dotenv
from pdf2image import convert_from_path
from PIL import Image
import time
import streamlit as st
import google.generativeai as genai
from pathlib import Path
from pdf2image import convert_from_path
from pathlib import Path
import os
import fitz 
from pathlib import Path
import time
from io import BytesIO
import os
from PIL import Image
import os
import google.generativeai as genai
st.title("DD with gemini-2.0-flash")
genai.configure(api_key=GOOGLE_API_KEY)


# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«Geminiã®APIã‚­ãƒ¼ã®å…¥åŠ›æ¬„ã‚’è¨­ã‘ã‚‹
with st.sidebar:
    gemini_api_key = st.text_input("Gemini API Key", key="chatbot_api_key", type="password")
    "[Get an Gemini API key](https://aistudio.google.com/app/apikey)"
    "[View the source code](https://github.com/danishi/streamlit-gemini-chatbot)"

st.title("âœ¨ Gemini Chatbot")
st.caption("ğŸš€ A Streamlit chatbot powered by Gemini")

pdf_folder = Path("/workspaces/streamit_sample_app/data/input")
pdf_folder.mkdir(parents=True, exist_ok=True)

# PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_pdf = st.file_uploader("PDFã‚’èª­ã¿è¾¼ã‚€", type=["pdf"])

if uploaded_pdf is not None:
    # ä¿å­˜ãƒ‘ã‚¹ã‚’è¨­å®š
    save_path = pdf_folder / uploaded_pdf.name
    
    # PDFã‚’ä¿å­˜
    with open(save_path, "wb") as f:
        f.write(uploaded_pdf.getbuffer())  # PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ãƒ•ã‚©ãƒ«ãƒ€
image_folder = Path("/workspaces/streamit_sample_app/data/output")  # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€
image_folder.mkdir(exist_ok=True)  # ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ä½œæˆ

# Open the first PDF file from the PDF folder
pdf_files = list(pdf_folder.glob("*.pdf"))  # Use the first PDF for example
if pdf_files:
    for pdf_file in pdf_files:
        doc = fitz.open(pdf_file)

        # PDFã”ã¨ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
        pdf_subfolder = image_folder / "image" / pdf_file.stem
        pdf_subfolder.mkdir(parents=True, exist_ok=True)

        # å„ãƒšãƒ¼ã‚¸ã‚’ç”»åƒã«å¤‰æ›
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            pix = page.get_pixmap()
            image_path = pdf_subfolder / f"{pdf_file.stem}_{page_num + 1}.jpg"
            pix.save(image_path)

        doc.close()
        st.success(f"ç”»åƒãŒ {pdf_subfolder} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
else:
    st.warning("PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒãªã‘ã‚Œã°åˆæœŸåŒ–
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º
for message in st.session_state.chat_history:
    st.chat_message(message["role"]).write(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãŒé€ä¿¡ã•ã‚ŒãŸéš›ã«å®Ÿè¡Œã•ã‚Œã‚‹å‡¦ç†
if prompt := st.chat_input("How can I help you?"):

    # APIã‚­ãƒ¼ã®ãƒã‚§ãƒƒã‚¯
    if not gemini_api_key:
        st.info("Please add your [Gemini API key](https://aistudio.google.com/app/apikey) to continue.")
        st.stop()

    # ãƒ¢ãƒ‡ãƒ«ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    genai.configure(api_key=gemini_api_key)
    model = genai.GenerativeModel('gemini-2.0-flash')

    # ãƒ¦ãƒ¼ã‚¶ã®å…¥åŠ›ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ ã—ç”»é¢è¡¨ç¤º
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—
    messages = []
    for message in st.session_state.chat_history:
        messages.append({
            "role": message["role"] if message["role"] == "user" else "model",
            'parts': message["content"]
        })

    # Geminiã¸å•ã„åˆã‚ã›ã‚’è¡Œã†
    response = model.generate_content(messages)

    # Geminiã®è¿”ç­”ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ ã—ç”»é¢è¡¨ç¤º
    st.session_state.chat_history.append({"role": "assistant", "content": response.text})
    st.chat_message("assistant").write(response.text)

import os
import google.generativeai as genai



# Create the model
generation_config = {
  "temperature": 1,
  "top_p": 0.95,
  "top_k": 40,
  "max_output_tokens": 8192,
  "response_mime_type": "text/plain",
}

model = genai.GenerativeModel(
  model_name="gemini-2.0-flash",
  generation_config=generation_config,
)

chat_session = model.start_chat(
  history=[
  ]
)

response = chat_session.send_message("INSERT_INPUT_HERE")

response.text.strip() if response and response.text else None
def process_with_gemini(image):
    """
    Send the page image to Gemini and extract structured Markdown content.
    """
    model = genai.GenerativeModel("gemini-2.0-flash")

    # API Rate Limiting
    time.sleep(2)
    
    prompt = """
    Extract all contents from the provided PDF page image and format it as Markdown in Japanese.  
    Do NOT extract repeated headers that appear on every page.  

    ### Guidelines: 
    - Structure text properly into headings, paragraphs, lists, and bullet points.  
    - Tables: If a table exists, extract it accurately and format it using proper Markdown table syntax.  
    - Graphs & Figures: If a graph or figure contains important numerical data, summarize key insights and represent them as a table if possible.  
    - Equations: If mathematical formulas appear, format them using LaTeX syntax within Markdown.  
    """

    response = model.generate_content([prompt, image])
    return response.text.strip() if response and response.text else None
from pathlib import Path
from PIL import Image

# ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã¨å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€

image_folder = Path("/workspaces/streamit_sample_app/data/output/image/å®šæ¬¾_SBIãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹")
output_dir = Path("/workspaces/streamit_sample_app/data/output/text docs")
output_dir.mkdir(exist_ok=True)
combined_dir = Path("/workspaces/streamit_sample_app/data/output")
# çµåˆç”¨ã®ãƒªã‚¹ãƒˆ
combined_content = []

# ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç•ªå·é †ã«å‡¦ç†
image_paths = sorted(image_folder.glob("*.jpg"), key=lambda x: int(x.stem.split('_')[-1]))  # Sort by number in filename

for image_path in image_paths:
    try:
        # ç”»åƒã‚’é–‹ã„ã¦å‡¦ç†
        img = Image.open(image_path).convert("RGB")  # RGBã«å¤‰æ›
        
        # Geminiã§å‡¦ç†
        markdown_content = process_with_gemini(img)
        
        # å†…å®¹ãŒã‚ã‚Œã°ãƒªã‚¹ãƒˆã«è¿½åŠ 
        if markdown_content:
            combined_content.append(markdown_content)
            print(f"Successfully processed {image_path}")
        else:
            print(f"No content extracted from {image_path}")
    
    except Exception as e:
        print(f"Error processing image {image_path}: {str(e)}")

# æœ€å¾Œã«ã™ã¹ã¦ã®å†…å®¹ã‚’1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
if combined_content:
    output_path = combined_dir / "combined_docs.md"
    try:
        with open(output_path, "w", encoding="utf-8") as f:
            f.write("\n\n".join(combined_content))  # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’çµåˆã—ã¦ä¿å­˜
        print(f"All markdown content has been successfully saved to {output_path}")
    except Exception as e:
        print(f"Error saving combined markdown: {str(e)}")
else:
    print("No content was extracted from any images.")
